{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq0mvproeGPZ",
        "colab_type": "code",
        "outputId": "de72f9b1-9b65-40b5-855c-59fdf9b5fd9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "source": [
        "!rm *.csv\n",
        "!rm cnn*\n",
        "!wget http://smartheatmap.ddns.net/dist/p.csv\n",
        "!wget http://smartheatmap.ddns.net/dist/n.csv\n",
        "!wget http://smartheatmap.ddns.net/dist/w2v.zip\n",
        "!unzip w2v.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.csv': No such file or directory\n",
            "rm: cannot remove 'cnn*': No such file or directory\n",
            "--2019-07-18 19:15:04--  http://smartheatmap.ddns.net/dist/p.csv\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27630235 (26M) [text/csv]\n",
            "Saving to: ‘p.csv’\n",
            "\n",
            "p.csv               100%[===================>]  26.35M  11.2MB/s    in 2.3s    \n",
            "\n",
            "2019-07-18 19:15:06 (11.2 MB/s) - ‘p.csv’ saved [27630235/27630235]\n",
            "\n",
            "--2019-07-18 19:15:09--  http://smartheatmap.ddns.net/dist/n.csv\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26037206 (25M) [text/csv]\n",
            "Saving to: ‘n.csv’\n",
            "\n",
            "n.csv               100%[===================>]  24.83M  10.9MB/s    in 2.3s    \n",
            "\n",
            "2019-07-18 19:15:11 (10.9 MB/s) - ‘n.csv’ saved [26037206/26037206]\n",
            "\n",
            "--2019-07-18 19:15:12--  http://smartheatmap.ddns.net/dist/w2v.zip\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1550406725 (1.4G) [application/zip]\n",
            "Saving to: ‘w2v.zip’\n",
            "\n",
            "w2v.zip             100%[===================>]   1.44G  7.47MB/s    in 4m 35s  \n",
            "\n",
            "2019-07-18 19:19:48 (5.37 MB/s) - ‘w2v.zip’ saved [1550406725/1550406725]\n",
            "\n",
            "Archive:  w2v.zip\n",
            "   creating: w2v/\n",
            "  inflating: w2v/tweets_model.w2v    \n",
            "  inflating: w2v/tweets_model.w2v.trainables.syn1neg.npy  \n",
            "  inflating: w2v/tweets_model.w2v.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KX9RZbbe4Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_positive = pd.read_csv('p.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "data_negative = pd.read_csv('n.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "\n",
        "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
        "raw_data = np.concatenate((data_positive['ttext'].values[:sample_size],\n",
        "                           data_negative['ttext'].values[:sample_size]), axis=0)\n",
        "labels = [1] * sample_size + [0] * sample_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdwh85CUfWVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def clear_text(text):\n",
        "    text = text.lower().replace(\"ё\", \"е\")\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
        "    text = re.sub('@[^\\s]+', 'USER', text)\n",
        "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "data = [clear_text(t) for t in raw_data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftfxJbGafvG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvrTTX8qsHPc",
        "colab_type": "code",
        "outputId": "978ac2cf-5ec9-4e0f-a1b8-d1035bb5eb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "SENTENCE_LENGTH = 26\n",
        "NUM = 100000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "def to_seq(x):\n",
        "    sequences = tokenizer.texts_to_sequences(x)\n",
        "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  \n",
        "x_train = to_seq(x_train)\n",
        "x_test = to_seq(x_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpaRSja3vSQi",
        "colab_type": "code",
        "outputId": "c8ae055b-7a3d-47c7-f248-48a4a7f2ba26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "wvmodel = Word2Vec.load(\"w2v/tweets_model.w2v\")\n",
        "\n",
        "DIM = wvmodel.vector_size \n",
        "embedding_matrix = np.zeros((NUM, DIM))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= NUM:\n",
        "        break\n",
        "    if word in wvmodel.wv.vocab.keys():\n",
        "        embedding_matrix[i] = wvmodel.wv[word]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQtEgsvesVmW",
        "colab_type": "code",
        "outputId": "63dc2360-99d6-4f47-fc41-a319470ae130",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "m_input = Input(shape=(SENTENCE_LENGTH,), dtype='int32')\n",
        "m_embed = Embedding(NUM, \n",
        "                    DIM, \n",
        "                    input_length=SENTENCE_LENGTH,\n",
        "                    weights=[embedding_matrix], \n",
        "                    trainable=True)(m_input)\n",
        "# DIM=1000\n",
        "# m_embed = Embedding(NUM, \n",
        "#                     DIM, \n",
        "#                     input_length=SENTENCE_LENGTH)(m_input)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 19:20:48.732491 140656627345280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 19:20:48.937486 140656627345280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 19:20:48.946720 140656627345280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0718 19:20:48.957391 140656627345280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0718 19:20:48.958178 140656627345280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPYFH7Dbv68i",
        "colab_type": "code",
        "outputId": "eff1c250-bda0-423d-856a-01a60b6652bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.layers import Dense, concatenate, Activation, Dropout, LSTM, CuDNNLSTM, GRU, CuDNNGRU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.regularizers import l1\n",
        "\n",
        "# x = Dropout(0.2)(m_embed)\n",
        "\n",
        "# conv_branches = []\n",
        "# for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]:\n",
        "#     for i in range(filters_count):\n",
        "#         i = Conv1D(filters=1, \n",
        "#                    kernel_size=size, \n",
        "#                    padding='valid', \n",
        "#                    activation='relu')(x)\n",
        "#         i = GlobalMaxPooling1D()(i)\n",
        "#         conv_branches.append(i)\n",
        "\n",
        "# x = concatenate(conv_branches, \n",
        "#                 axis=1)\n",
        "\n",
        "# x = Dropout(0.2)(x)\n",
        "# x = Dense(30, activation='relu')(x)\n",
        "# x = Dense(1)(x)`\n",
        "\n",
        "# m_output = Activation('sigmoid')(x)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(NUM, \n",
        "#                     DIM, \n",
        "#                     input_length=SENTENCE_LENGTH,\n",
        "#                     weights=[embedding_matrix], \n",
        "#                     trainable=False))\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# model.add(CuDNNLSTM(200, return_sequences=True))\n",
        "# model.add(CuDNNLSTM(10))\n",
        "\n",
        "# model.add(Dropout(0.1))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model = Model(inputs=[m_input], \n",
        "#               outputs=[m_output])\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(NUM, \n",
        "                    DIM, \n",
        "                    input_length=SENTENCE_LENGTH))\n",
        "\n",
        "model.add(CuDNNGRU(units=200, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(CuDNNGRU(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 19:20:53.778035 140656627345280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_OIR_F85pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        \n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4YngqaPx8aH",
        "colab_type": "code",
        "outputId": "c6b02781-6d01-4642-e56e-d2cc2a4eca61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False), \n",
        "              metrics=['accuracy',\n",
        "                       precision, \n",
        "                       recall, \n",
        "                       f1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 19:20:53.988393 140656627345280 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0718 19:20:53.998507 140656627345280 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqV2fGm_yGFF",
        "colab_type": "code",
        "outputId": "c804a67d-2ea4-4cf3-9c5a-07c9dcbffff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"cnn-{epoch:02d}-{val_f1:.2f}.hdf5\", \n",
        "                             monitor='val_f1', \n",
        "                             save_best_only=True, \n",
        "                             mode='max', \n",
        "                             period=1)\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    batch_size=32, \n",
        "                    epochs=10, \n",
        "                    validation_split=0.25, \n",
        "                    callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 134307 samples, validate on 44769 samples\n",
            "Epoch 1/10\n",
            "134307/134307 [==============================] - 63s 466us/step - loss: 0.5877 - acc: 0.6696 - precision: 0.6912 - recall: 0.6433 - f1: 0.6347 - val_loss: 0.5302 - val_acc: 0.7257 - val_precision: 0.7530 - val_recall: 0.6707 - val_f1: 0.7024\n",
            "Epoch 2/10\n",
            "134307/134307 [==============================] - 57s 426us/step - loss: 0.5058 - acc: 0.7445 - precision: 0.7594 - recall: 0.7315 - f1: 0.7321 - val_loss: 0.5032 - val_acc: 0.7480 - val_precision: 0.7868 - val_recall: 0.6803 - val_f1: 0.7228\n",
            "Epoch 3/10\n",
            "134307/134307 [==============================] - 57s 426us/step - loss: 0.4683 - acc: 0.7736 - precision: 0.7820 - recall: 0.7702 - f1: 0.7655 - val_loss: 0.4894 - val_acc: 0.7571 - val_precision: 0.7411 - val_recall: 0.7914 - val_f1: 0.7595\n",
            "Epoch 4/10\n",
            "134307/134307 [==============================] - 58s 429us/step - loss: 0.4394 - acc: 0.7927 - precision: 0.7997 - recall: 0.7877 - f1: 0.7848 - val_loss: 0.4822 - val_acc: 0.7646 - val_precision: 0.7907 - val_recall: 0.7201 - val_f1: 0.7473\n",
            "Epoch 5/10\n",
            "134307/134307 [==============================] - 59s 437us/step - loss: 0.4146 - acc: 0.8093 - precision: 0.8176 - recall: 0.8033 - f1: 0.8021 - val_loss: 0.4868 - val_acc: 0.7635 - val_precision: 0.7922 - val_recall: 0.7145 - val_f1: 0.7450\n",
            "Epoch 6/10\n",
            "134307/134307 [==============================] - 58s 429us/step - loss: 0.3917 - acc: 0.8240 - precision: 0.8337 - recall: 0.8152 - f1: 0.8167 - val_loss: 0.4877 - val_acc: 0.7647 - val_precision: 0.7857 - val_recall: 0.7279 - val_f1: 0.7496\n",
            "Epoch 7/10\n",
            "134307/134307 [==============================] - 58s 432us/step - loss: 0.3699 - acc: 0.8362 - precision: 0.8449 - recall: 0.8279 - f1: 0.8295 - val_loss: 0.5049 - val_acc: 0.7637 - val_precision: 0.7530 - val_recall: 0.7855 - val_f1: 0.7631\n",
            "Epoch 8/10\n",
            "134307/134307 [==============================] - 60s 445us/step - loss: 0.3487 - acc: 0.8494 - precision: 0.8584 - recall: 0.8406 - f1: 0.8433 - val_loss: 0.5195 - val_acc: 0.7593 - val_precision: 0.7296 - val_recall: 0.8250 - val_f1: 0.7689\n",
            "Epoch 9/10\n",
            "134307/134307 [==============================] - 58s 429us/step - loss: 0.3279 - acc: 0.8597 - precision: 0.8692 - recall: 0.8506 - f1: 0.8544 - val_loss: 0.5250 - val_acc: 0.7657 - val_precision: 0.7637 - val_recall: 0.7695 - val_f1: 0.7607\n",
            "Epoch 10/10\n",
            "134307/134307 [==============================] - 58s 433us/step - loss: 0.3069 - acc: 0.8728 - precision: 0.8825 - recall: 0.8631 - f1: 0.8677 - val_loss: 0.5661 - val_acc: 0.7552 - val_precision: 0.7206 - val_recall: 0.8338 - val_f1: 0.7678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ueu6hRGTLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "7d67d4c6-d08e-41e0-ff52-0bc354ac2418"
      },
      "source": [
        "model.predict(to_seq([\"Зачем мне подрывать и без того не самую безупречную репутацию кураторов?\",\n",
        "                       \"сломанная лавочка\",\n",
        "                       \"Ну это же логично, что я дождался, пока ты прочтешь и удалил\",\n",
        "                       \"трансгендер на улице\",\n",
        "                       \"США\",\n",
        "                       \"СССР\",\n",
        "                       \"фашист\",\n",
        "                       \"на улице поставили хреновую красивую скамейку\",\n",
        "                       \"на улице хрено поставили красивую скамейку\",\n",
        "                       \"на улице Ленина поставили хреновую скамейку\",\n",
        "                       \"красивую скамейку\",\n",
        "                       \"мне нравится эта хрень, но будет нереально круто\",\n",
        "                       \"Жить конечно тут наверное нет\",\n",
        "                       \"Очень-очень красиво, сказочно, солнечно, жарко, волшебно....можно много слов написать, и все они будут про это не забываемое место. Я  не знаю у кого как. Но я очень люблю Сочи-Адлер и люблю тут отдыхать с детьми и одна и с подругами и вообще. Жить конечно тут наверное нет. Но летом сюда-это точно. На все лето, сюда☺☺☺🤩🤩🤩🤩🤩\",\n",
        "                       \"эта скамейка очень красивая\",\n",
        "                       \"сегодня было грустно\",\n",
        "                       \"эта скамейка полная чушь\"]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05207121],\n",
              "       [0.27718973],\n",
              "       [0.7104188 ],\n",
              "       [0.11550653],\n",
              "       [0.2089504 ],\n",
              "       [0.82411873],\n",
              "       [0.04311556],\n",
              "       [0.30116308],\n",
              "       [0.30116308],\n",
              "       [0.8714996 ],\n",
              "       [0.0971269 ],\n",
              "       [0.8966627 ],\n",
              "       [0.04124203],\n",
              "       [0.914395  ],\n",
              "       [0.2629144 ],\n",
              "       [0.00165039],\n",
              "       [0.03896639]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}