{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cudnnlstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq0mvproeGPZ",
        "colab_type": "code",
        "outputId": "0475980a-98f2-4f82-a1f4-a8a67ab7e343",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        }
      },
      "source": [
        "!rm *.csv\n",
        "!rm cnn*\n",
        "!wget http://smartheatmap.ddns.net/dist/p.csv\n",
        "!wget http://smartheatmap.ddns.net/dist/n.csv\n",
        "!wget http://smartheatmap.ddns.net/dist/w2v.zip\n",
        "!unzip w2v.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.csv': No such file or directory\n",
            "rm: cannot remove 'cnn*': No such file or directory\n",
            "--2019-07-18 15:55:20--  http://smartheatmap.ddns.net/dist/p.csv\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27630235 (26M) [text/csv]\n",
            "Saving to: ‘p.csv’\n",
            "\n",
            "p.csv               100%[===================>]  26.35M  7.32MB/s    in 3.6s    \n",
            "\n",
            "2019-07-18 15:55:23 (7.32 MB/s) - ‘p.csv’ saved [27630235/27630235]\n",
            "\n",
            "--2019-07-18 15:55:25--  http://smartheatmap.ddns.net/dist/n.csv\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26037206 (25M) [text/csv]\n",
            "Saving to: ‘n.csv’\n",
            "\n",
            "n.csv               100%[===================>]  24.83M  8.32MB/s    in 3.0s    \n",
            "\n",
            "2019-07-18 15:55:28 (8.32 MB/s) - ‘n.csv’ saved [26037206/26037206]\n",
            "\n",
            "--2019-07-18 15:55:29--  http://smartheatmap.ddns.net/dist/w2v.zip\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1550406725 (1.4G) [application/zip]\n",
            "Saving to: ‘w2v.zip’\n",
            "\n",
            "w2v.zip             100%[===================>]   1.44G  13.9MB/s    in 2m 9s   \n",
            "\n",
            "2019-07-18 15:57:38 (11.5 MB/s) - ‘w2v.zip’ saved [1550406725/1550406725]\n",
            "\n",
            "Archive:  w2v.zip\n",
            "   creating: w2v/\n",
            "  inflating: w2v/tweets_model.w2v    \n",
            "  inflating: w2v/tweets_model.w2v.trainables.syn1neg.npy  \n",
            "  inflating: w2v/tweets_model.w2v.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KX9RZbbe4Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_positive = pd.read_csv('p.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "data_negative = pd.read_csv('n.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "\n",
        "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
        "raw_data = np.concatenate((data_positive['ttext'].values[:sample_size],\n",
        "                           data_negative['ttext'].values[:sample_size]), axis=0)\n",
        "labels = [1] * sample_size + [0] * sample_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdwh85CUfWVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def clear_text(text):\n",
        "    text = text.lower().replace(\"ё\", \"е\")\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
        "    text = re.sub('@[^\\s]+', 'USER', text)\n",
        "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "data = [clear_text(t) for t in raw_data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftfxJbGafvG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvrTTX8qsHPc",
        "colab_type": "code",
        "outputId": "66a384a1-8368-4083-e8a6-99d82eec7413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "SENTENCE_LENGTH = 26\n",
        "NUM = 100000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "def to_seq(x):\n",
        "    sequences = tokenizer.texts_to_sequences(x)\n",
        "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  \n",
        "x_train = to_seq(x_train)\n",
        "x_test = to_seq(x_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpaRSja3vSQi",
        "colab_type": "code",
        "outputId": "add4fa2f-949f-4ebe-add3-5c575ff81d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "wvmodel = Word2Vec.load(\"w2v/tweets_model.w2v\")\n",
        "\n",
        "DIM = wvmodel.vector_size \n",
        "embedding_matrix = np.zeros((NUM, DIM))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= NUM:\n",
        "        break\n",
        "    if word in wvmodel.wv.vocab.keys():\n",
        "        embedding_matrix[i] = wvmodel.wv[word]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQtEgsvesVmW",
        "colab_type": "code",
        "outputId": "159f68c8-625c-4345-f1de-623771c2cc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "m_input = Input(shape=(SENTENCE_LENGTH,), dtype='int32')\n",
        "# m_embed = Embedding(NUM, \n",
        "#                     DIM, \n",
        "#                     input_length=SENTENCE_LENGTH,\n",
        "#                     weights=[embedding_matrix], \n",
        "#                     trainable=True)(m_input)\n",
        "DIM=300\n",
        "m_embed = Embedding(NUM, \n",
        "                    DIM, \n",
        "                    input_length=SENTENCE_LENGTH)(m_input)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 15:58:39.197914 140439064582016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 15:58:39.233949 140439064582016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 15:58:39.240551 140439064582016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPYFH7Dbv68i",
        "colab_type": "code",
        "outputId": "d818bd0c-349d-41aa-ef8a-4893dac9e3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.layers import Dense, concatenate, Activation, Dropout, LSTM, CuDNNLSTM, TimeDistributed\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.regularizers import l1\n",
        "\n",
        "# x = Dropout(0.2)(m_embed)\n",
        "\n",
        "# conv_branches = []\n",
        "# for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]:\n",
        "#     for i in range(filters_count):\n",
        "#         i = Conv1D(filters=1, \n",
        "#                    kernel_size=size, \n",
        "#                    padding='valid', \n",
        "#                    activation='relu')(x)\n",
        "#         i = GlobalMaxPooling1D()(i)\n",
        "#         conv_branches.append(i)\n",
        "\n",
        "# x = concatenate(conv_branches, \n",
        "#                 axis=1)\n",
        "\n",
        "# x = Dropout(0.2)(x)\n",
        "# x = Dense(30, activation='relu')(x)\n",
        "# x = Dense(1)(x)\n",
        "\n",
        "# m_output = Activation('sigmoid')(x)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(NUM, \n",
        "                    DIM, \n",
        "                    input_length=SENTENCE_LENGTH))\n",
        "\n",
        "model.add(CuDNNLSTM(units=DIM, return_sequences=True))  \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(CuDNNLSTM(units=50, return_sequences=True))  \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(CuDNNLSTM(units=50))  \n",
        "model.add(Dropout(0.2))  \n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model = Model(inputs=[m_input], \n",
        "#               outputs=[m_output])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 15:58:41.000008 140439064582016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0718 15:58:41.011883 140439064582016 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_OIR_F85pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        \n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4YngqaPx8aH",
        "colab_type": "code",
        "outputId": "17c36f89-7a93-49a4-99b5-13b7ced3fbbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy',\n",
        "                       precision, \n",
        "                       recall, \n",
        "                       f1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 15:58:41.339756 140439064582016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0718 15:58:41.362867 140439064582016 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0718 15:58:41.369194 140439064582016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqV2fGm_yGFF",
        "colab_type": "code",
        "outputId": "e8a49652-68c8-422b-d1b3-ad3fa4ac6202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"cnn-{epoch:02d}-{val_f1:.2f}.hdf5\", \n",
        "                             monitor='val_f1', \n",
        "                             save_best_only=True, \n",
        "                             mode='max', \n",
        "                             period=1)\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    batch_size=32, \n",
        "                    epochs=10, \n",
        "                    validation_split=0.25, \n",
        "                    callbacks = [checkpoint])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 134307 samples, validate on 44769 samples\n",
            "Epoch 1/10\n",
            "134307/134307 [==============================] - 147s 1ms/step - loss: 0.4855 - acc: 0.7579 - precision: 0.7622 - recall: 0.7517 - f1: 0.7479 - val_loss: 0.4485 - val_acc: 0.7828 - val_precision: 0.7806 - val_recall: 0.7860 - val_f1: 0.7780\n",
            "Epoch 2/10\n",
            "134307/134307 [==============================] - 139s 1ms/step - loss: 0.2960 - acc: 0.8737 - precision: 0.8790 - recall: 0.8665 - f1: 0.8688 - val_loss: 0.4946 - val_acc: 0.7736 - val_precision: 0.7852 - val_recall: 0.7528 - val_f1: 0.7629\n",
            "Epoch 3/10\n",
            "134307/134307 [==============================] - 140s 1ms/step - loss: 0.1479 - acc: 0.9412 - precision: 0.9457 - recall: 0.9360 - f1: 0.9388 - val_loss: 0.7355 - val_acc: 0.7608 - val_precision: 0.7549 - val_recall: 0.7732 - val_f1: 0.7580\n",
            "Epoch 4/10\n",
            "134307/134307 [==============================] - 139s 1ms/step - loss: 0.0790 - acc: 0.9689 - precision: 0.9718 - recall: 0.9657 - f1: 0.9678 - val_loss: 1.0654 - val_acc: 0.7573 - val_precision: 0.7744 - val_recall: 0.7266 - val_f1: 0.7434\n",
            "Epoch 5/10\n",
            "134307/134307 [==============================] - 139s 1ms/step - loss: 0.0490 - acc: 0.9816 - precision: 0.9835 - recall: 0.9797 - f1: 0.9810 - val_loss: 1.1685 - val_acc: 0.7467 - val_precision: 0.7497 - val_recall: 0.7404 - val_f1: 0.7389\n",
            "Epoch 6/10\n",
            "134307/134307 [==============================] - 138s 1ms/step - loss: 0.0339 - acc: 0.9868 - precision: 0.9885 - recall: 0.9851 - f1: 0.9863 - val_loss: 1.2356 - val_acc: 0.7456 - val_precision: 0.7534 - val_recall: 0.7297 - val_f1: 0.7352\n",
            "Epoch 7/10\n",
            "134307/134307 [==============================] - 139s 1ms/step - loss: 0.0246 - acc: 0.9909 - precision: 0.9918 - recall: 0.9900 - f1: 0.9906 - val_loss: 1.4366 - val_acc: 0.7459 - val_precision: 0.7439 - val_recall: 0.7490 - val_f1: 0.7406\n",
            "Epoch 8/10\n",
            "134307/134307 [==============================] - 139s 1ms/step - loss: 0.0183 - acc: 0.9931 - precision: 0.9939 - recall: 0.9923 - f1: 0.9929 - val_loss: 1.4125 - val_acc: 0.7431 - val_precision: 0.7264 - val_recall: 0.7794 - val_f1: 0.7463\n",
            "Epoch 9/10\n",
            "134307/134307 [==============================] - 139s 1ms/step - loss: 0.0143 - acc: 0.9948 - precision: 0.9956 - recall: 0.9941 - f1: 0.9947 - val_loss: 1.5663 - val_acc: 0.7429 - val_precision: 0.7445 - val_recall: 0.7385 - val_f1: 0.7354\n",
            "Epoch 10/10\n",
            "134307/134307 [==============================] - 139s 1ms/step - loss: 0.0123 - acc: 0.9956 - precision: 0.9959 - recall: 0.9952 - f1: 0.9954 - val_loss: 1.5933 - val_acc: 0.7402 - val_precision: 0.7496 - val_recall: 0.7213 - val_f1: 0.7287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ueu6hRGTLV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "cf56e2f1-487f-48c6-862a-5bfe7eecf31a"
      },
      "source": [
        "model.predict(to_seq([\"Зачем мне подрывать и без того не самую безупречную репутацию кураторов?\",\n",
        "                       \"сломанная лавочка\",\n",
        "                       \"Ну это же логично, что я дождался, пока ты прочтешь и удалил\",\n",
        "                       \"трансгендер на улице\",\n",
        "                       \"США\",\n",
        "                       \"СССР\",\n",
        "                       \"фашист\",\n",
        "                       \"на улице поставили хреновую красивую скамейку\",\n",
        "                       \"на улице хрено поставили красивую скамейку\",\n",
        "                       \"на улице Ленина поставили хреновую скамейку\",\n",
        "                       \"красивую скамейку\",\n",
        "                       \"мне нравится эта хрень, но будет нереально круто\",\n",
        "                       \"Жить конечно тут наверное нет\",\n",
        "                       \"Очень-очень красиво, сказочно, солнечно, жарко, волшебно....можно много слов написать, и все они будут про это не забываемое место. Я  не знаю у кого как. Но я очень люблю Сочи-Адлер и люблю тут отдыхать с детьми и одна и с подругами и вообще. Жить конечно тут наверное нет. Но летом сюда-это точно. На все лето, сюда☺☺☺🤩🤩🤩🤩🤩\",\n",
        "                       \"эта скамейка очень красивая\",\n",
        "                       \"сегодня было грустно\",\n",
        "                       \"эта скамейка полная чушь\"]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.6044459e-03],\n",
              "       [4.3852100e-01],\n",
              "       [8.7648630e-05],\n",
              "       [6.1606467e-03],\n",
              "       [1.5796575e-01],\n",
              "       [5.0603300e-01],\n",
              "       [8.3029270e-04],\n",
              "       [9.9909830e-01],\n",
              "       [9.9909830e-01],\n",
              "       [9.7110498e-01],\n",
              "       [4.2142719e-02],\n",
              "       [9.9966228e-01],\n",
              "       [2.0614266e-04],\n",
              "       [1.0982230e-01],\n",
              "       [9.4761878e-02],\n",
              "       [5.1975250e-05],\n",
              "       [2.7257418e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}