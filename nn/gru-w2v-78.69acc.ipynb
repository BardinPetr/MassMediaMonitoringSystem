{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gru.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq0mvproeGPZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "feefd6d0-a7ce-4094-a98e-adb899558d28"
      },
      "source": [
        "!rm *.csv\n",
        "!rm cnn*\n",
        "!wget http://smartheatmap.ddns.net/dist/p.csv\n",
        "!wget http://smartheatmap.ddns.net/dist/n.csv\n",
        "!wget http://smartheatmap.ddns.net/dist/w2v.zip\n",
        "!unzip w2v.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.csv': No such file or directory\n",
            "rm: cannot remove 'cnn*': No such file or directory\n",
            "--2019-07-18 19:15:07--  http://smartheatmap.ddns.net/dist/p.csv\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 27630235 (26M) [text/csv]\n",
            "Saving to: ‚Äòp.csv‚Äô\n",
            "\n",
            "p.csv               100%[===================>]  26.35M  6.51MB/s    in 4.7s    \n",
            "\n",
            "2019-07-18 19:15:17 (5.57 MB/s) - ‚Äòp.csv‚Äô saved [27630235/27630235]\n",
            "\n",
            "--2019-07-18 19:15:21--  http://smartheatmap.ddns.net/dist/n.csv\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26037206 (25M) [text/csv]\n",
            "Saving to: ‚Äòn.csv‚Äô\n",
            "\n",
            "n.csv               100%[===================>]  24.83M  6.84MB/s    in 3.6s    \n",
            "\n",
            "2019-07-18 19:15:25 (6.84 MB/s) - ‚Äòn.csv‚Äô saved [26037206/26037206]\n",
            "\n",
            "--2019-07-18 19:15:36--  http://smartheatmap.ddns.net/dist/w2v.zip\n",
            "Resolving smartheatmap.ddns.net (smartheatmap.ddns.net)... 188.120.231.51\n",
            "Connecting to smartheatmap.ddns.net (smartheatmap.ddns.net)|188.120.231.51|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1550406725 (1.4G) [application/zip]\n",
            "Saving to: ‚Äòw2v.zip‚Äô\n",
            "\n",
            "w2v.zip             100%[===================>]   1.44G  6.88MB/s    in 3m 37s  \n",
            "\n",
            "2019-07-18 19:19:13 (6.82 MB/s) - ‚Äòw2v.zip‚Äô saved [1550406725/1550406725]\n",
            "\n",
            "Archive:  w2v.zip\n",
            "   creating: w2v/\n",
            "  inflating: w2v/tweets_model.w2v    \n",
            "  inflating: w2v/tweets_model.w2v.trainables.syn1neg.npy  \n",
            "  inflating: w2v/tweets_model.w2v.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KX9RZbbe4Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_positive = pd.read_csv('p.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "data_negative = pd.read_csv('n.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "\n",
        "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
        "raw_data = np.concatenate((data_positive['ttext'].values[:sample_size],\n",
        "                           data_negative['ttext'].values[:sample_size]), axis=0)\n",
        "labels = [1] * sample_size + [0] * sample_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdwh85CUfWVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def clear_text(text):\n",
        "    text = text.lower().replace(\"—ë\", \"–µ\")\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
        "    text = re.sub('@[^\\s]+', 'USER', text)\n",
        "    text = re.sub('[^a-zA-Z–∞-—è–ê-–Ø1-9]+', ' ', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "data = [clear_text(t) for t in raw_data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftfxJbGafvG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvrTTX8qsHPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aaa3b351-28fc-4e0b-a44a-91e6b9f30f7b"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "SENTENCE_LENGTH = 26\n",
        "NUM = 100000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "def to_seq(x):\n",
        "    sequences = tokenizer.texts_to_sequences(x)\n",
        "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  \n",
        "x_train = to_seq(x_train)\n",
        "x_test = to_seq(x_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpaRSja3vSQi",
        "colab_type": "code",
        "outputId": "f14dd960-557c-40bc-e0b9-2a65a20c68b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "wvmodel = Word2Vec.load(\"w2v/tweets_model.w2v\")\n",
        "\n",
        "DIM = wvmodel.vector_size \n",
        "embedding_matrix = np.zeros((NUM, DIM))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= NUM:\n",
        "        break\n",
        "    if word in wvmodel.wv.vocab.keys():\n",
        "        embedding_matrix[i] = wvmodel.wv[word]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQtEgsvesVmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "153a01b4-7a24-4e90-d034-672490ba9838"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "m_input = Input(shape=(SENTENCE_LENGTH,), dtype='int32')\n",
        "m_embed = Embedding(NUM, \n",
        "                    DIM, \n",
        "                    input_length=SENTENCE_LENGTH,\n",
        "                    weights=[embedding_matrix], \n",
        "                    trainable=True)(m_input)\n",
        "# DIM=1000\n",
        "# m_embed = Embedding(NUM, \n",
        "#                     DIM, \n",
        "#                     input_length=SENTENCE_LENGTH)(m_input)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0718 19:20:11.093771 140188089657216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0718 19:20:11.129042 140188089657216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0718 19:20:11.136617 140188089657216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0718 19:20:11.146897 140188089657216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0718 19:20:11.147745 140188089657216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPYFH7Dbv68i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "589238a0-ed66-4d11-f2f0-e41c489add65"
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.layers import Dense, concatenate, Activation, Dropout, LSTM, CuDNNLSTM, GRU, CuDNNGRU\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "from keras.regularizers import l1\n",
        "\n",
        "# x = Dropout(0.2)(m_embed)\n",
        "\n",
        "# conv_branches = []\n",
        "# for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]:\n",
        "#     for i in range(filters_count):\n",
        "#         i = Conv1D(filters=1, \n",
        "#                    kernel_size=size, \n",
        "#                    padding='valid', \n",
        "#                    activation='relu')(x)\n",
        "#         i = GlobalMaxPooling1D()(i)\n",
        "#         conv_branches.append(i)\n",
        "\n",
        "# x = concatenate(conv_branches, \n",
        "#                 axis=1)\n",
        "\n",
        "# x = Dropout(0.2)(x)\n",
        "# x = Dense(30, activation='relu')(x)\n",
        "# x = Dense(1)(x)\n",
        "\n",
        "# m_output = Activation('sigmoid')(x)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(NUM, \n",
        "#                     DIM, \n",
        "#                     input_length=SENTENCE_LENGTH,\n",
        "#                     weights=[embedding_matrix], \n",
        "#                     trainable=False))\n",
        "# model.add(Dropout(0.3))\n",
        "\n",
        "# model.add(CuDNNLSTM(200, return_sequences=True))\n",
        "# model.add(CuDNNLSTM(10))\n",
        "\n",
        "# model.add(Dropout(0.1))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model = Model(inputs=[m_input], \n",
        "#               outputs=[m_output])\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(NUM, \n",
        "                    DIM, \n",
        "                    input_length=SENTENCE_LENGTH,\n",
        "                    weights=[embedding_matrix], \n",
        "                    trainable=True))\n",
        "\n",
        "model.add(CuDNNGRU(units=200, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(CuDNNGRU(units=50))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 19:20:15.895425 140188089657216 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_OIR_F85pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        \n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4YngqaPx8aH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "b4bd446d-281e-4208-ca2a-f1d66360ffed"
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.SGD(lr=0.01, decay=1e-7, momentum=0.9, nesterov=False), \n",
        "              metrics=['accuracy',\n",
        "                       precision, \n",
        "                       recall, \n",
        "                       f1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0718 19:20:16.097321 140188089657216 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0718 19:20:16.107912 140188089657216 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqV2fGm_yGFF",
        "colab_type": "code",
        "outputId": "b5bb6810-5b9d-4d29-c67c-5f07d13fd0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"cnn-{epoch:02d}-{val_f1:.2f}.hdf5\", \n",
        "                             monitor='val_f1', \n",
        "                             save_best_only=True, \n",
        "                             mode='max', \n",
        "                             period=1)\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    batch_size=32, \n",
        "                    epochs=10, \n",
        "                    validation_split=0.25, \n",
        "                    callbacks = [checkpoint])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 134307 samples, validate on 44769 samples\n",
            "Epoch 1/10\n",
            "134307/134307 [==============================] - 58s 433us/step - loss: 0.5036 - acc: 0.7480 - precision: 0.7546 - recall: 0.7406 - f1: 0.7382 - val_loss: 0.4724 - val_acc: 0.7680 - val_precision: 0.7601 - val_recall: 0.7839 - val_f1: 0.7664\n",
            "Epoch 2/10\n",
            "134307/134307 [==============================] - 54s 401us/step - loss: 0.4611 - acc: 0.7753 - precision: 0.7783 - recall: 0.7730 - f1: 0.7682 - val_loss: 0.4611 - val_acc: 0.7762 - val_precision: 0.8038 - val_recall: 0.7312 - val_f1: 0.7597\n",
            "Epoch 3/10\n",
            "134307/134307 [==============================] - 54s 403us/step - loss: 0.4406 - acc: 0.7879 - precision: 0.7905 - recall: 0.7843 - f1: 0.7808 - val_loss: 0.4515 - val_acc: 0.7803 - val_precision: 0.7841 - val_recall: 0.7753 - val_f1: 0.7741\n",
            "Epoch 4/10\n",
            "134307/134307 [==============================] - 54s 406us/step - loss: 0.4249 - acc: 0.7978 - precision: 0.8008 - recall: 0.7932 - f1: 0.7908 - val_loss: 0.4470 - val_acc: 0.7833 - val_precision: 0.7966 - val_recall: 0.7625 - val_f1: 0.7734\n",
            "Epoch 5/10\n",
            "134307/134307 [==============================] - 54s 402us/step - loss: 0.4096 - acc: 0.8078 - precision: 0.8117 - recall: 0.8030 - f1: 0.8012 - val_loss: 0.4435 - val_acc: 0.7857 - val_precision: 0.7836 - val_recall: 0.7899 - val_f1: 0.7815\n",
            "Epoch 6/10\n",
            "134307/134307 [==============================] - 54s 403us/step - loss: 0.3948 - acc: 0.8175 - precision: 0.8210 - recall: 0.8132 - f1: 0.8114 - val_loss: 0.4472 - val_acc: 0.7876 - val_precision: 0.7917 - val_recall: 0.7809 - val_f1: 0.7809\n",
            "Epoch 7/10\n",
            "134307/134307 [==============================] - 54s 402us/step - loss: 0.3797 - acc: 0.8256 - precision: 0.8289 - recall: 0.8213 - f1: 0.8196 - val_loss: 0.4536 - val_acc: 0.7869 - val_precision: 0.7742 - val_recall: 0.8108 - val_f1: 0.7872\n",
            "Epoch 8/10\n",
            "134307/134307 [==============================] - 54s 402us/step - loss: 0.3652 - acc: 0.8351 - precision: 0.8393 - recall: 0.8297 - f1: 0.8291 - val_loss: 0.4513 - val_acc: 0.7859 - val_precision: 0.8003 - val_recall: 0.7619 - val_f1: 0.7751\n",
            "Epoch 9/10\n",
            "134307/134307 [==============================] - 54s 405us/step - loss: 0.3493 - acc: 0.8437 - precision: 0.8480 - recall: 0.8383 - f1: 0.8381 - val_loss: 0.4730 - val_acc: 0.7860 - val_precision: 0.7700 - val_recall: 0.8162 - val_f1: 0.7872\n",
            "Epoch 10/10\n",
            "134307/134307 [==============================] - 54s 403us/step - loss: 0.3312 - acc: 0.8535 - precision: 0.8566 - recall: 0.8499 - f1: 0.8484 - val_loss: 0.4719 - val_acc: 0.7850 - val_precision: 0.7798 - val_recall: 0.7944 - val_f1: 0.7818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ueu6hRGTLV",
        "colab_type": "code",
        "outputId": "bb6c8637-d5aa-43de-fb30-82f02ee0abc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "model.predict(to_seq([\"–ó–∞—á–µ–º –º–Ω–µ –ø–æ–¥—Ä—ã–≤–∞—Ç—å –∏ –±–µ–∑ —Ç–æ–≥–æ –Ω–µ —Å–∞–º—É—é –±–µ–∑—É–ø—Ä–µ—á–Ω—É—é —Ä–µ–ø—É—Ç–∞—Ü–∏—é –∫—É—Ä–∞—Ç–æ—Ä–æ–≤?\",\n",
        "                       \"—Å–ª–æ–º–∞–Ω–Ω–∞—è –ª–∞–≤–æ—á–∫–∞\",\n",
        "                       \"–ù—É —ç—Ç–æ –∂–µ –ª–æ–≥–∏—á–Ω–æ, —á—Ç–æ —è –¥–æ–∂–¥–∞–ª—Å—è, –ø–æ–∫–∞ —Ç—ã –ø—Ä–æ—á—Ç–µ—à—å –∏ —É–¥–∞–ª–∏–ª\",\n",
        "                       \"—Ç—Ä–∞–Ω—Å–≥–µ–Ω–¥–µ—Ä –Ω–∞ —É–ª–∏—Ü–µ\",\n",
        "                       \"–°–®–ê\",\n",
        "                       \"–°–°–°–†\",\n",
        "                       \"—Ñ–∞—à–∏—Å—Ç\",\n",
        "                       \"–Ω–∞ —É–ª–∏—Ü–µ –ø–æ—Å—Ç–∞–≤–∏–ª–∏ —Ö—Ä–µ–Ω–æ–≤—É—é –∫—Ä–∞—Å–∏–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–Ω–∞ —É–ª–∏—Ü–µ —Ö—Ä–µ–Ω–æ –ø–æ—Å—Ç–∞–≤–∏–ª–∏ –∫—Ä–∞—Å–∏–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–Ω–∞ —É–ª–∏—Ü–µ –õ–µ–Ω–∏–Ω–∞ –ø–æ—Å—Ç–∞–≤–∏–ª–∏ —Ö—Ä–µ–Ω–æ–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–∫—Ä–∞—Å–∏–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —ç—Ç–∞ —Ö—Ä–µ–Ω—å, –Ω–æ –±—É–¥–µ—Ç –Ω–µ—Ä–µ–∞–ª—å–Ω–æ –∫—Ä—É—Ç–æ\",\n",
        "                       \"–ñ–∏—Ç—å –∫–æ–Ω–µ—á–Ω–æ —Ç—É—Ç –Ω–∞–≤–µ—Ä–Ω–æ–µ –Ω–µ—Ç\",\n",
        "                       \"–û—á–µ–Ω—å-–æ—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤–æ, —Å–∫–∞–∑–æ—á–Ω–æ, —Å–æ–ª–Ω–µ—á–Ω–æ, –∂–∞—Ä–∫–æ, –≤–æ–ª—à–µ–±–Ω–æ....–º–æ–∂–Ω–æ –º–Ω–æ–≥–æ —Å–ª–æ–≤ –Ω–∞–ø–∏—Å–∞—Ç—å, –∏ –≤—Å–µ –æ–Ω–∏ –±—É–¥—É—Ç –ø—Ä–æ —ç—Ç–æ –Ω–µ –∑–∞–±—ã–≤–∞–µ–º–æ–µ –º–µ—Å—Ç–æ. –Ø  –Ω–µ –∑–Ω–∞—é —É –∫–æ–≥–æ –∫–∞–∫. –ù–æ —è –æ—á–µ–Ω—å –ª—é–±–ª—é –°–æ—á–∏-–ê–¥–ª–µ—Ä –∏ –ª—é–±–ª—é —Ç—É—Ç –æ—Ç–¥—ã—Ö–∞—Ç—å —Å –¥–µ—Ç—å–º–∏ –∏ –æ–¥–Ω–∞ –∏ —Å –ø–æ–¥—Ä—É–≥–∞–º–∏ –∏ –≤–æ–æ–±—â–µ. –ñ–∏—Ç—å –∫–æ–Ω–µ—á–Ω–æ —Ç—É—Ç –Ω–∞–≤–µ—Ä–Ω–æ–µ –Ω–µ—Ç. –ù–æ –ª–µ—Ç–æ–º —Å—é–¥–∞-—ç—Ç–æ —Ç–æ—á–Ω–æ. –ù–∞ –≤—Å–µ –ª–µ—Ç–æ, —Å—é–¥–∞‚ò∫‚ò∫‚ò∫ü§©ü§©ü§©ü§©ü§©\",\n",
        "                       \"—ç—Ç–∞ —Å–∫–∞–º–µ–π–∫–∞ –æ—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤–∞—è\",\n",
        "                       \"—Å–µ–≥–æ–¥–Ω—è –±—ã–ª–æ –≥—Ä—É—Å—Ç–Ω–æ\",\n",
        "                       \"—ç—Ç–∞ —Å–∫–∞–º–µ–π–∫–∞ –ø–æ–ª–Ω–∞—è —á—É—à—å\"]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11605415],\n",
              "       [0.03370479],\n",
              "       [0.98206496],\n",
              "       [0.04564625],\n",
              "       [0.08090109],\n",
              "       [0.04567707],\n",
              "       [0.04721913],\n",
              "       [0.67029256],\n",
              "       [0.67029256],\n",
              "       [0.8545147 ],\n",
              "       [0.11996683],\n",
              "       [0.9884217 ],\n",
              "       [0.03369442],\n",
              "       [0.90419555],\n",
              "       [0.69665116],\n",
              "       [0.0017674 ],\n",
              "       [0.12721549]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}