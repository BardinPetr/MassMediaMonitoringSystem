{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1-77",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tq0mvproeGPZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !rm *.csv\n",
        "# !wget http://smartheatmap.ddns.net/dist/p.csv\n",
        "# !wget http://smartheatmap.ddns.net/dist/n.csv\n",
        "# !pip3 install wldhx.yadisk-direct hyperas hyperopt\n",
        "# !curl -L $(yadisk-direct https://yadi.sk/d/NmzmzI1_v9tecQ) -o w2v.zip\n",
        "# !unzip w2v.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KX9RZbbe4Rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data_positive = pd.read_csv('p.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "data_negative = pd.read_csv('n.csv', sep=';', error_bad_lines=False, usecols=['ttext'])\n",
        "\n",
        "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
        "raw_data = np.concatenate((data_positive['ttext'].values[:sample_size],\n",
        "                           data_negative['ttext'].values[:sample_size]), axis=0)\n",
        "labels = [1] * sample_size + [0] * sample_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdwh85CUfWVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def clear_text(text):\n",
        "    text = text.lower().replace(\"—ë\", \"–µ\")\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', text)\n",
        "    text = re.sub('@[^\\s]+', 'USER', text)\n",
        "    text = re.sub('[^a-zA-Z–∞-—è–ê-–Ø1-9]+', ' ', text)\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "data = [clear_text(t) for t in raw_data]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftfxJbGafvG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvrTTX8qsHPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "38594d49-7c4e-4a87-e3bc-32d281cde8b6"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "\n",
        "SENTENCE_LENGTH = 26\n",
        "NUM = 100000\n",
        "\n",
        "tokenizer = Tokenizer(num_words=NUM)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "\n",
        "def to_seq(x):\n",
        "    sequences = tokenizer.texts_to_sequences(x)\n",
        "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
        "\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "  \n",
        "x_train = to_seq(x_train)\n",
        "x_test = to_seq(x_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpaRSja3vSQi",
        "colab_type": "code",
        "outputId": "75910e3a-a506-476b-cbdf-6a9d9de1966e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "wvmodel = Word2Vec.load(\"w2v/tweets_model.w2v\")\n",
        "\n",
        "DIM = wvmodel.vector_size \n",
        "embedding_matrix = np.zeros((NUM, DIM))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= NUM:\n",
        "        break\n",
        "    if word in wvmodel.wv.vocab.keys():\n",
        "        embedding_matrix[i] = wvmodel.wv[word]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQtEgsvesVmW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "88140fce-a9a8-4b5f-c10c-63fcaeee1cc8"
      },
      "source": [
        "from keras.layers import Input\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "m_input = Input(shape=(SENTENCE_LENGTH,), dtype='int32')\n",
        "m_embed = Embedding(NUM, \n",
        "                    DIM, \n",
        "                    input_length=SENTENCE_LENGTH,\n",
        "                    weights=[embedding_matrix], \n",
        "                    trainable=True)(m_input)\n",
        "# DIM=1000\n",
        "# m_embed = Embedding(NUM, \n",
        "#                     DIM, \n",
        "#                     input_length=SENTENCE_LENGTH)(m_input)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0717 12:35:28.823692 139847317223296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0717 12:35:28.850658 139847317223296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0717 12:35:28.854964 139847317223296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0717 12:35:28.869721 139847317223296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0717 12:35:28.871300 139847317223296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPYFH7Dbv68i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "676c96b1-333d-449e-945a-94107b79ee77"
      },
      "source": [
        "from keras import optimizers\n",
        "from keras.layers import Dense, concatenate, Activation, Dropout\n",
        "from keras.models import Model\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.pooling import GlobalMaxPooling1D\n",
        "\n",
        "x = Dropout(0.2)(m_embed)\n",
        "\n",
        "conv_branches = []\n",
        "for size, filters_count in [(2, 10), (3, 10), (4, 10), (5, 10)]:\n",
        "    for i in range(filters_count):\n",
        "        i = Conv1D(filters=1, \n",
        "                   kernel_size=size, \n",
        "                   padding='valid', \n",
        "                   activation='relu')(x)\n",
        "        i = GlobalMaxPooling1D()(i)\n",
        "        conv_branches.append(i)\n",
        "\n",
        "x = concatenate(conv_branches, \n",
        "                axis=1)\n",
        "\n",
        "x = Dropout(0.2)(x)\n",
        "x = Dense(30, activation='relu')(x)\n",
        "x = Dense(1)(x)\n",
        "\n",
        "m_output = Activation('sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=[m_input], \n",
        "              outputs=[m_output])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0717 12:35:29.822127 139847317223296 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca_OIR_F85pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "\n",
        "    Only computes a batch-wise average of precision.\n",
        "\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    \"\"\"Recall metric.\n",
        "\n",
        "    Only computes a batch-wise average of recall.\n",
        "\n",
        "    Computes the recall, a metric for multi-label classification of\n",
        "    how many relevant items are selected.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        \n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4YngqaPx8aH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "f164ca6c-86f2-465a-804b-785e4d40a747"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy',\n",
        "                       precision, \n",
        "                       recall, \n",
        "                       f1])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0717 12:35:30.874514 139847317223296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0717 12:35:30.916135 139847317223296 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRXnAy-avLxd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c534489a-daea-4c94-c398-ef6cbb7c2e19"
      },
      "source": [
        "rm cnn*"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'cnn*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqV2fGm_yGFF",
        "colab_type": "code",
        "outputId": "e10ef0a9-268c-42ea-96e8-f4666873916b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"cnn-{epoch:02d}-{val_f1:.2f}.hdf5\", \n",
        "                             monitor='val_f1', \n",
        "                             save_best_only=True, \n",
        "                             mode='max', \n",
        "                             period=1)\n",
        "\n",
        "history = model.fit(x_train, \n",
        "                    y_train, \n",
        "                    batch_size=32, \n",
        "                    epochs=10, \n",
        "                    validation_split=0.25, \n",
        "                    callbacks = [checkpoint])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 134307 samples, validate on 44769 samples\n",
            "Epoch 1/10\n",
            "134307/134307 [==============================] - 311s 2ms/step - loss: 0.5442 - acc: 0.7120 - precision: 0.7160 - recall: 0.7022 - f1: 0.7002 - val_loss: 0.4793 - val_acc: 0.7654 - val_precision: 0.7693 - val_recall: 0.7586 - val_f1: 0.7580\n",
            "Epoch 2/10\n",
            "134307/134307 [==============================] - 308s 2ms/step - loss: 0.4588 - acc: 0.7789 - precision: 0.7822 - recall: 0.7743 - f1: 0.7718 - val_loss: 0.4554 - val_acc: 0.7793 - val_precision: 0.7844 - val_recall: 0.7711 - val_f1: 0.7720\n",
            "Epoch 3/10\n",
            "134307/134307 [==============================] - 304s 2ms/step - loss: 0.4100 - acc: 0.8114 - precision: 0.8186 - recall: 0.8017 - f1: 0.8044 - val_loss: 0.4531 - val_acc: 0.7803 - val_precision: 0.7921 - val_recall: 0.7611 - val_f1: 0.7704\n",
            "Epoch 4/10\n",
            "134307/134307 [==============================] - 306s 2ms/step - loss: 0.3612 - acc: 0.8395 - precision: 0.8482 - recall: 0.8268 - f1: 0.8326 - val_loss: 0.4681 - val_acc: 0.7801 - val_precision: 0.7842 - val_recall: 0.7736 - val_f1: 0.7732\n",
            "Epoch 5/10\n",
            "134307/134307 [==============================] - 303s 2ms/step - loss: 0.3169 - acc: 0.8644 - precision: 0.8725 - recall: 0.8535 - f1: 0.8586 - val_loss: 0.4849 - val_acc: 0.7757 - val_precision: 0.7799 - val_recall: 0.7684 - val_f1: 0.7685\n",
            "Epoch 6/10\n",
            "134307/134307 [==============================] - 304s 2ms/step - loss: 0.2809 - acc: 0.8818 - precision: 0.8896 - recall: 0.8717 - f1: 0.8769 - val_loss: 0.5188 - val_acc: 0.7690 - val_precision: 0.7723 - val_recall: 0.7633 - val_f1: 0.7621\n",
            "Epoch 7/10\n",
            "  4352/134307 [..............................] - ETA: 4:41 - loss: 0.2486 - acc: 0.9014 - precision: 0.9056 - recall: 0.9021 - f1: 0.9005"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E0717 13:06:31.570133 139847317223296 ultratb.py:147] Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-12-3b7c340669eb>\", line 14, in <module>\n",
            "    callbacks = [checkpoint])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\", line 1039, in fit\n",
            "    validation_steps=validation_steps)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\", line 199, in fit_loop\n",
            "    outs = f(ins_batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2715, in __call__\n",
            "    return self._call(inputs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\", line 2675, in _call\n",
            "    fetched = self._callable_fn(*array_vals)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1458, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
            "    newpath = join(path, name)\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 89, in join\n",
            "    elif not path or path.endswith(sep):\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ueu6hRGTLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(to_seq([\"–ó–∞—á–µ–º –º–Ω–µ –ø–æ–¥—Ä—ã–≤–∞—Ç—å –∏ –±–µ–∑ —Ç–æ–≥–æ –Ω–µ —Å–∞–º—É—é –±–µ–∑—É–ø—Ä–µ—á–Ω—É—é —Ä–µ–ø—É—Ç–∞—Ü–∏—é –∫—É—Ä–∞—Ç–æ—Ä–æ–≤?\",\n",
        "                       \"—Å–ª–æ–º–∞–Ω–Ω–∞—è –ª–∞–≤–æ—á–∫–∞\",\n",
        "                       \"–ù—É —ç—Ç–æ –∂–µ –ª–æ–≥–∏—á–Ω–æ, —á—Ç–æ —è –¥–æ–∂–¥–∞–ª—Å—è, –ø–æ–∫–∞ —Ç—ã –ø—Ä–æ—á—Ç–µ—à—å –∏ —É–¥–∞–ª–∏–ª\",\n",
        "                       \"—Ç—Ä–∞–Ω—Å–≥–µ–Ω–¥–µ—Ä –Ω–∞ —É–ª–∏—Ü–µ\",\n",
        "                       \"–°–®–ê\",\n",
        "                       \"–°–°–°–†\",\n",
        "                       \"—Ñ–∞—à–∏—Å—Ç\",\n",
        "                       \"–Ω–∞ —É–ª–∏—Ü–µ –ø–æ—Å—Ç–∞–≤–∏–ª–∏ —Ö—Ä–µ–Ω–æ–≤—É—é –∫—Ä–∞—Å–∏–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–Ω–∞ —É–ª–∏—Ü–µ —Ö—Ä–µ–Ω–æ –ø–æ—Å—Ç–∞–≤–∏–ª–∏ –∫—Ä–∞—Å–∏–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–Ω–∞ —É–ª–∏—Ü–µ –õ–µ–Ω–∏–Ω–∞ –ø–æ—Å—Ç–∞–≤–∏–ª–∏ —Ö—Ä–µ–Ω–æ–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–∫—Ä–∞—Å–∏–≤—É—é —Å–∫–∞–º–µ–π–∫—É\",\n",
        "                       \"–º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è —ç—Ç–∞ —Ö—Ä–µ–Ω—å, –Ω–æ –±—É–¥–µ—Ç –Ω–µ—Ä–µ–∞–ª—å–Ω–æ –∫—Ä—É—Ç–æ\",\n",
        "                       \"–ñ–∏—Ç—å –∫–æ–Ω–µ—á–Ω–æ —Ç—É—Ç –Ω–∞–≤–µ—Ä–Ω–æ–µ –Ω–µ—Ç\",\n",
        "                       \"–û—á–µ–Ω—å-–æ—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤–æ, —Å–∫–∞–∑–æ—á–Ω–æ, —Å–æ–ª–Ω–µ—á–Ω–æ, –∂–∞—Ä–∫–æ, –≤–æ–ª—à–µ–±–Ω–æ....–º–æ–∂–Ω–æ –º–Ω–æ–≥–æ —Å–ª–æ–≤ –Ω–∞–ø–∏—Å–∞—Ç—å, –∏ –≤—Å–µ –æ–Ω–∏ –±—É–¥—É—Ç –ø—Ä–æ —ç—Ç–æ –Ω–µ –∑–∞–±—ã–≤–∞–µ–º–æ–µ –º–µ—Å—Ç–æ. –Ø  –Ω–µ –∑–Ω–∞—é —É –∫–æ–≥–æ –∫–∞–∫. –ù–æ —è –æ—á–µ–Ω—å –ª—é–±–ª—é –°–æ—á–∏-–ê–¥–ª–µ—Ä –∏ –ª—é–±–ª—é —Ç—É—Ç –æ—Ç–¥—ã—Ö–∞—Ç—å —Å –¥–µ—Ç—å–º–∏ –∏ –æ–¥–Ω–∞ –∏ —Å –ø–æ–¥—Ä—É–≥–∞–º–∏ –∏ –≤–æ–æ–±—â–µ. –ñ–∏—Ç—å –∫–æ–Ω–µ—á–Ω–æ —Ç—É—Ç –Ω–∞–≤–µ—Ä–Ω–æ–µ –Ω–µ—Ç. –ù–æ –ª–µ—Ç–æ–º —Å—é–¥–∞-—ç—Ç–æ —Ç–æ—á–Ω–æ. –ù–∞ –≤—Å–µ –ª–µ—Ç–æ, —Å—é–¥–∞‚ò∫‚ò∫‚ò∫ü§©ü§©ü§©ü§©ü§©\",\n",
        "                       \"—ç—Ç–∞ —Å–∫–∞–º–µ–π–∫–∞ –æ—á–µ–Ω—å –∫—Ä–∞—Å–∏–≤–∞—è\",\n",
        "                       \"—Å–µ–≥–æ–¥–Ω—è –±—ã–ª–æ –≥—Ä—É—Å—Ç–Ω–æ\",\n",
        "                       \"—ç—Ç–∞ —Å–∫–∞–º–µ–π–∫–∞ –ø–æ–ª–Ω–∞—è —á—É—à—å\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}